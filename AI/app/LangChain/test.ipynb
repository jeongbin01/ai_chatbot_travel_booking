{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05da0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    title_en: str = Field(description=\"\")\n",
    "    title_ko: str = Field(description=\"\")\n",
    "    contents: str = Field(default=\"\")\n",
    "    detail_contents: str = Field(description=\"\")\n",
    "    urls: str = Field(description=\"\")\n",
    "\n",
    "class QandAChain:\n",
    "    def __init__(self):\n",
    "        base_path = os.getcwd() \n",
    "        # base_path = os.path.dirna/e(os.path.abspath(__file__))  # 현재 파일의 경로\n",
    "        file_path = os.path.join(base_path, 'prompt', 'QandAPrompt.yaml')\n",
    "\n",
    "        #with open(file_path, 'r') as f:\n",
    "        #    self.__prompt_template = yaml.load(f, Loader=yaml.SafeLoader)['template']\n",
    "        \n",
    "        self.__prompt_template = \"\"\"\n",
    "        너는 여행 정보를 제공하는 AI야.\n",
    "\n",
    "        사용자의 질문에 아래 JSON 형식으로 답변해 줘:\n",
    "\n",
    "        {format_instructions}\n",
    "\n",
    "        질문: {question}\n",
    "        \"\"\"\n",
    "\n",
    "        self.__model = ChatOpenAI(\n",
    "            temperature = 0.1,\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            max_tokens = 2048,\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        self.__parser = JsonOutputParser(pydantic_object=Answer)\n",
    "        # self.__parser = StrOutputParser()\n",
    "\n",
    "    def main_chain_invoke(self, question):\n",
    "        prompt = PromptTemplate.from_template(self.__prompt_template)\n",
    "        prompt = prompt.partial(format_instructions=self.__parser.get_format_instructions())\n",
    "\n",
    "        chain = prompt | self.__model | self.__parser\n",
    "\n",
    "        result = chain.invoke({\"question\": question})\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d48cdd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title_en': 'What is LangChain?', 'title_ko': 'LangChain이란?', 'contents': 'LangChain은 자연어 처리(NLP) 및 인공지능(AI) 모델을 활용하여 다양한 애플리케이션을 구축할 수 있도록 돕는 프레임워크입니다.', 'detail_contents': 'LangChain은 언어 모델을 사용하여 데이터 처리, 대화형 AI, 정보 검색, 자동화된 작업 등을 수행할 수 있는 도구와 라이브러리를 제공합니다. 이 프레임워크는 사용자가 쉽게 언어 모델을 통합하고, 다양한 데이터 소스와 상호작용할 수 있도록 설계되었습니다.', 'urls': 'https://langchain.readthedocs.io/'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    chain = QandAChain()\n",
    "    result = chain.main_chain_invoke(\"LangChain이란?\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ad751",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08b1001",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-osm-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
